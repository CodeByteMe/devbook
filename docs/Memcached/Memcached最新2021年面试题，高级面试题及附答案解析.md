# Memcached最新2021年面试题，高级面试题及附答案解析







### 1、如何实现集群中的session共享存储？

Session是运行在一台服务器上的，所有的访问都会到达我们的唯一服务器上，这样我们可以根据客户端传来的sessionID，来获取session，或在对应Session不存在的情况下（session 生命周期到了/用户第一次登录），创建一个新的Session；但是，如果我们在集群环境下，假设我们有两台服务器A，B，用户的请求会由Nginx服务器进行转发（别的方案也是同理），用户登录时，Nginx将请求转发至服务器A上，A创建了新的session，并将SessionID返回给客户端，用户在浏览其他页面时，客户端验证登录状态，Nginx将请求转发至服务器B，由于B上并没有对应客户端发来sessionId的session，所以会重新创建一个新的session，并且再将这个新的sessionID返回给客户端，这样，我们可以想象一下，用户每一次操作都有1/2的概率进行再次的登录，这样不仅对用户体验特别差，还会让服务器上的session激增，加大服务器的运行压力。

**为了解决集群环境下的seesion共享问题，共有4种解决方案：**

**1、** 粘性session

粘性session是指Ngnix每次都将同一用户的所有请求转发至同一台服务器上，即将用户与服务器绑定。

**2、** 服务器session复制

即每次session发生变化时，创建或者修改，就广播给所有集群中的服务器，使所有的服务器上的session相同。

**3、** session共享

缓存session，使用Redis， Memcached。

**4、** session持久化

将session存储至数据库中，像操作数据一样才做session。


### 2、Memcached服务在企业集群架构中有哪些应用场景？

**一、作为数据库的前端缓存应用**

**a、完整缓存（易），静态缓存**

例如：商品分类（京东），以及商品信息，可事先放在内存里，然后再对外提供数据访问，这种先放到内存，我们称之为预热，（先把数据存缓存中），用户访问时可以只读取Memcached缓存，不读取数据库了。

**b、执点缓存（难）**

需要前端web程序配合，只缓存热点的数据，即缓存经常被访问的数据。

先预热数据库里的基础数据，然后在动态更新，选读取缓存，如果缓存里没有对应的数据，程序再去读取数据库，然后程序把读取的新数据放入缓存存储。

**特殊说明 ：**

**1、** 如果碰到电商秒杀等高并发的业务，一定要事先预热，或者其它思想实现，例如：称杀只是获取资格，而不是瞬间秒杀到手商品。

那么什么是获取资格？_

**2、** 就是在数据库中，把0标成1.就有资格啦。再慢慢的去领取商品订单。因为秒杀过程太长会占用服务器资源。

**3、** 如果数据更新，同时触发缓存更新，防止给用户过期数据。

**4、** 对于持久化缓存存储系统，例如：Redis，可以替代一部分数据库的存储，一些简单的数据业务，投票，统计，好友关注，商品分类等。nosql= not only sql

**二、作业集群的session会话共享存储**

**1、** Memcached服务在不同企业业务应用场景中的工作流程

当web程序需要访问后端数据库获取数据时会优先访问Memcached内存缓存，如果缓存中有数据就直接获取返回前端服务及用户，如果没有数据（没有命中），在由程序请求后端的数据库服务器，获取到对应的数据后，除了返回给前端服务及用户数据外，还会把数据放到Memcached内存中进行缓存，等待下次请求被访问，Memcache内存始终是数据库的挡箭牌，从而大大的减轻数据库的访问压力，提高整个网站架构的响应速度，提升了用户体验。

当程序更新，修改或删除数据库中已有的数据时，会同时发送请求通知Memcached已经缓存的同一个ID内容的旧数据失效，从而保证Memcache中数据和数据库中的数据一致。

如果在高并发场合，除了通知Memcached过程的缓存失效外，还会通过相关机制，使得在用户访问新数据前，通过程序预先把更新过的数据推送到memcache中缓存起来，这样可以减少数据库的访问压力，提升Memcached中缓存命中率。

数据库插件可以再写入更新数据库后，自动抛给MC缓存起来，自身不Cache.

**2、** Memcached服务分布式集群如何实现？

**特殊说明：**

Memcached集群和web服务集群是不一样的，所有Memcached的数据总和才是数据库的数据。每台Memcached都是部分数据。

（一台Memcached的数据，就是一部分MySQL数据库的数据）

**1、** 程序端实现

程序加载所有mc的ip列表，通过对key做hash (一致性哈希算法)

例如：web1 (key)===>对应A,B,C,D,E,F,G…..若干台服务器。（通过哈希算法实现）

**2、** 负载均衡器

通过对key做hash (一致性哈希算法)

一致哈希算法的目的是不但保证每个对象只请求一个对应的服务器，而且当节点宕机，缓存服务器的更新重新分配比例降到最低。


### 3、简述Memcached内存管理机制原理？

早期的Memcached内存管理方式是通过malloc的分配的内存，使用完后通过free来回收内存，这种方式容易产生内存碎片，并降低操作系统对内存的管理效率。加重操作系统内存管理器的负担，最坏的情况下，会导致操作系统比Memcached进程本身还慢，为了解决这个问题，Slab Allocation内存分配机制就延生了。

**现在Memcached利用Slab Allocation机制来分配和管理内存**

SlabAllocation机制原理是按照预先规定的大小，将分配给Memcached的内存分割成特定长度的内存块（chunk)，再把尺寸相同的内存块，分成组

（chunks slab class),这些内存块不会释放，可以重复利用。

而且，slab allocator还有重复使用已分配的内存的目的。 也就是说，分配到的内存不会释放，而是重复利用。

**Slab Allocation的主要术语**

**Page**

分配给Slab的内存空间，默认是1MB。分配给Slab之后根据slab的大小切分成chunk。

**Chunk**

用于缓存记录的内存空间。

**SlabClass**

特定大小的chunk的组。

集群架构方面的问题


### 4、如果缓存数据在导出导入之间过期了，您又怎么处理这些数据呢？

因此，批量导出导入数据并不像您想象中的那么有用。不过在一个场景倒是很有用。如果您有大量的从不变化的数据，并且希望缓存很快热（warm）起来，批量导入缓存数据是很有帮助的。虽然这个场景并不典型，但却经常发生，因此我们会考虑在将来实现批量导出导入的功能。

如果一个Memcached节点down了让您很痛苦，那么您还会陷入其他很多麻烦。您的系统太脆弱了。您需要做一些优化工作。比如处理”惊群”问题（比如 Memcached节点都失效了，反复的查询让您的数据库不堪重负…这个问题在FAQ的其他提到过），或者优化不好的查询。记住，Memcached 并不是您逃避优化查询的借口。


### 5、Memcached是怎么工作的？

Memcached的神奇来自两阶段哈希（two-stage hash）。Memcached就像一个巨大的、存储了很多`<key,value>`对的哈希表。通过key，可以存储或查询任意的数据。

客户端可以把数据存储在多台Memcached上。当查询数据时，客户端首先参考节点列表计算出key的哈希值（阶段一哈希），进而选中一个节点；客户端将请求发送给选中的节点，然后Memcached节点通过一个内部的哈希算法（阶段二哈希），查找真正的数据（item）。


### 6、Memcached是如何做身份验证的？

没有身份认证机制！Memcached是运行在应用下层的软件（身份验证应该是应用上层的职责）。Memcached的客户端和服务器端之所以是轻量级的，部分原因就是完全没有实现身份验证机制。这样，Memcached可以很快地创建新连接，服务器端也无需任何配置。

如果您希望限制访问，您可以使用防火墙，或者让Memcached监听unix domain socket。


### 7、Memcached是原子的吗？

所有的被发送到Memcached的单个命令是完全原子的。如果您针对同一份数据同时发送了一个set命令和一个get命令，它们不会影响对方。它们将被串行化、先后执行。即使在多线程模式，所有的命令都是原子的，除非程序有bug:)

命令序列不是原子的。如果您通过get命令获取了一个item，修改了它，然后想把它set回Memcached，我们不保证这个item没有被其他进程（process，未必是操作系统中的进程）操作过。在并发的情况下，您也可能覆写了一个被其他进程set的item。

Memcached 1.2.5以及更高版本，提供了gets和cas命令，它们可以解决上面的问题。如果您使用gets命令查询某个key的item，Memcached会给您返回该item当前值的唯一标识。如果您覆写了这个item并想把它写回到Memcached中，您可以通过cas命令把那个唯一标识一起发送给 Memcached。如果该item存放在Memcached中的唯一标识与您提供的一致，您的写操作将会成功。如果另一个进程在这期间也修改了这个 item，那么该item存放在Memcached中的唯一标识将会改变，您的写操作就会失败


### 8、Memcached最大的优势是什么？

Memcached最大的好处就是它带来了极佳的水平可扩展性，特别是在一个巨大的系统中。由于客户端自己做了一次哈希，那么我们很容易增加大量Memcached到集群中。Memcached之间没有相互通信，因此不会增加 Memcached的负载；没有多播协议，不会网络通信量爆炸（implode）。Memcached的集群很好用。内存不够了？增加几台Memcached吧；CPU不够用了？再增加几台吧；有多余的内存？在增加几台吧，不要浪费了。

基于Memcached的基本原则，可以相当轻松地构建出不同类型的缓存架构。除了这篇FAQ，在其他地方很容易找到详细资料的。


### 9、Memcached的多线程是什么？如何使用它们？

线程就是定律（threads rule）！在Steven Grimm和Facebook的努力下，Memcached 1.2及更高版本拥有了多线程模式。多线程模式允许Memcached能够充分利用多个CPU，并在CPU之间共享所有的缓存数据。Memcached使用一种简单的锁机制来保证数据更新操作的互斥。相比在同一个物理机器上运行多个Memcached实例，这种方式能够更有效地处理multi gets。

如果您的系统负载并不重，也许您不需要启用多线程工作模式。如果您在运行一个拥有大规模硬件的、庞大的网站，您将会看到多线程的好处。

简单地总结一下：命令解析（Memcached在这里花了大部分时间）可以运行在多线程模式下。Memcached内部对数据的操作是基于很多全局锁的（因此这部分工作不是多线程的）。未来对多线程模式的改进，将移除大量的全局锁，提高Memcached在负载极高的场景下的性能。


### 10、Memcached的内存分配器是如何工作的？为什么不适用malloc/free！？为何要使用slabs？

实际上，这是一个编译时选项。默认会使用内部的slab分配器。您确实确实应该使用内建的slab分配器。最早的时候，Memcached只使用 malloc/free来管理内存。然而，这种方式不能与OS的内存管理以前很好地工作。反复地malloc/free造成了内存碎片，OS最终花费大量的时间去查找连续的内存块来满足malloc的请求，而不是运行Memcached进程。如果您不同意，当然可以使用malloc！只是不要在邮件列表中抱怨啊

slab分配器就是为了解决这个问题而生的。内存被分配并划分成chunks，一直被重复使用。因为内存被划分成大小不等的slabs，如果item 的大小与被选择存放它的slab不是很合适的话，就会浪费一些内存。Steven Grimm正在这方面已经做出了有效的改进。


### 11、Memcached最大能存储多大的单个item？
### 12、什么是二进制协议，我该关注吗？
### 13、Memcached的cache机制是怎样的？
### 14、Memcached和服务器的local cache（比如PHP的APC、mmap文件等）相比，有什么优缺点？
### 15、如何将Memcached中item批量导入导出？
### 16、Memcached能接受的key的最大长度是多少？
### 17、Memcached与Redis的区别？
### 18、Memcached是什么，有什么作用？
### 19、Memcached能够更有效地使用内存吗？
### 20、Memcached服务特点及工作原理是什么？
### 21、Memcached如何实现冗余机制？
### 22、Memcached如何处理容错的？
### 23、Memcached和MySQL的query




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)




## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
