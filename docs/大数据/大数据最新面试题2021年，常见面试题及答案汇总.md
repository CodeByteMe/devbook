# 大数据最新面试题2021年，常见面试题及答案汇总







### 1、怎么保证Kafka集群的负载均衡？

一个parttion只能被一个消费者消费，

一个消费者可以消费多个partition，如果设置分区数量小于消费者数量，则会导致消费者空闲，所以设置参数 partition数量一定要大于consumer数量

partition数量一定要大于broker数量（节点数量），这样leader的分区就会均匀分布在各个broker上，实现负载的均衡

Kafka命令使用


### 2、怎么样才能实现去掉reduce阶段

去掉之后就不排序了，不进行shuffle操作了


### 3、上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。

方案1：上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map/搜索二叉树/红黑树等来进行统计次数。然后就是取出前N个出现次数最多的数据了，可以用第2题提到的堆机制完成。


### 4、hive 跟hbase的区别

共同点都是用hadoop作为底层存储

区别：hive是为了减少mrjobs编写工作的批处理系统，处理速度慢。hive本身不存储数据和计算数据，依赖于hadoop，纯逻辑表

hbase是为了hadoop对实时操作的缺陷的项目，处理速度快，是物理表，提供一个超大的内存hash表，方便查询操作

如果全表扫描用 hive+hadoop

如果用索引查询与hbase+hadoop

是处理数据库文件还是读取文本文件

先读取文本文件进行清洗，然后放入hdfs，进行处理

或者直接读取MySQL中格式化数据


### 5、请写出以下的shell命令

**1、** 杀死一个job

**2、** 删除hdfs上的 /tmp/aaa目录

**3、** 加入一个新的存储节点和删除一个节点需要执行的命令

**4、** hadoop job –list 得到job的id，然后执 行 hadoop job -kill jobId就可以杀死一个指定jobId的job工作了。

**5、** hadoopfs -rmr /tmp/aaa

**6、** 增加一个新的节点在新的几点上执行

Hadoop  daemon.sh start  datanode

Hadooop daemon.sh  start  tasktracker/nodemanager

下线时，要在conf目录下的excludes文件中列出要下线的datanode机器主机名

然后在主节点中执行  hadoop  dfsadmin  -refreshnodes  à下线一个datanode

删除一个节点的时候，只需要在主节点执行

hadoop mradmin -refreshnodes —下线一个tasktracker/nodemanager


### 6、MapReduce运行原理

离线计算框架，过程分为split map shuffle reduce四个过程

架构节点有：Jobtracker TaskTracker

Split将文件分割，传输到mapper，mapper接收KV形式的数据，经过处理，再传到shuffle过程。

Shuffle先进行HashPartition或者自定义的partition，会有数据倾斜和reduce的负载均衡问题；再进行排序，默认按字典排序；为减少mapper输出数据，再根据key进行合并，相同key的数据value会被合并；最后分组形成（key,value{}）形式的数据，输出到下一阶段

Reduce输入的数据就变成了，key+迭代器形式的数据，再进行处理。

Hadoop中的MapReduce是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的式并 行处理上T级别的数据集。

一个MapReduce作业（job）通常会把输入的数据集切分为若干独立的数据块，由map任务（task）以完全并行的方式处理它们。框架会对map的输出先进行排序，然后把结果输入给reduce任务。通常作业的输入和输出都会被存储在文件系统中。整个框架负责任务的调度和监控，以及重新执行已经失败的任务。

通常，MapReduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点通常在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。

MapReduce框架由一个单独的master JobTracker和每个集群节点一个slave TaskTracker共同组成。master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上，master监控它们的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务


### 7、在Hadoop_PID_DIR中，PID代表了什么？

PID代表了“Process ID”。


### 8、如何退出输入模式？

退出输入的方式有：1，按ESC；2，键入q（如果你没有输入任何当下）或者键入wq（如果你已经输入当下），并且按下Enter。


### 9、VM是否可以称为Pseudo？

不是，两个事物，同时Pseudo只针对Hadoop。


### 10、如果在SSH中添加key，是否还需要设置密码？

是的，即使在SSH中添加了key，还是需要设置密码。


### 11、Hadoop的shuffle过程
### 12、这会导致安全问题吗？
### 13、HBase的特点是什么？
### 14、为什么SSH本地主机需要密码？
### 15、hive底层与数据库交互原理
### 16、hive底层与数据库交互原理
### 17、Redis，传统数据库，hbase，hive每个之间的区别
### 18、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
### 19、mapreduce的原理
### 20、我们使用Ubuntu及Cloudera，那么我们该去哪里下载Hadoop，或者是默认就与Ubuntu一起安装？
### 21、请说明hive中Sort By、Order By、Cluster By，Distribute By各代表什么意思？
### 22、你认为用java ， streaming ， pipe方式开发map/reduce ， 各有哪些优点
### 23、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。
### 24、hadoop-metrics.properties文件的作用是？
### 25、Kafka与传统消息队列的区别
### 26、什么是udf
### 27、RDD缓存
### 28、是客户端还是Namenode决定输入的分片？
### 29、fs.mapr.working.dir只是单一的目录？
### 30、假如一个分区的数据逐步错误怎么通过hivesql删除
### 31、Masters由什么组成？
### 32、收集日志的模型




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)




## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
